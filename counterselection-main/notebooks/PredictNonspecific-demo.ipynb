{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils import *\n",
    "from inference import *\n",
    "global_aa = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to example sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data\n",
    "- The example sequences are ELISA verified specific and nonspecific binders to Xolair/Herceptin. The idea is that the model trained on **unrelated** sticky targets can identify sequences that would bind promiscuously to many targets, including to both Xolair or Herceptin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.read_csv(\"../data/data/TableS1.csv\", header=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One can apply these models to any sequences in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         EIRVPILIFFDY\n",
       "1         KIHRRFVVSFDY\n",
       "2         ELDKYPLVYFDY\n",
       "3         ERRQVPQIWFDY\n",
       "4      DTGFHDQDQSHYMDY\n",
       "5         PAAPFYDEPFDY\n",
       "6         ADPYVYHEWLDY\n",
       "7        QWEKEWVEAQFDY\n",
       "8         EIDYYPLIIFDY\n",
       "9         HHHPKYWGGFDY\n",
       "10        ELRLVPLIGFDY\n",
       "11        EYSAWPLIYFDY\n",
       "12        YGWWHWEAPFDY\n",
       "13    DKWPDSTWYGFYEFDY\n",
       "14         GATYYEEWMDY\n",
       "15         ELVYYHEYLDY\n",
       "16    EDRHQRHFQIQISFDY\n",
       "17        EYRQAPLVDFDY\n",
       "18    ELRGGWRIPVPIWFDY\n",
       "19        ELSLWPLLIFDY\n",
       "20         PGGYYDEAFDY\n",
       "21        DPYYWWEWEFDY\n",
       "22    DPWSWPSIDLYWGFDY\n",
       "23        DWSDVLSPEFDY\n",
       "24        EQDYHPLIWFDY\n",
       "25        FSFRRFVQSLDY\n",
       "26        DQSKYPLVYFDY\n",
       "27        EERRPPLVIFDY\n",
       "28    DYIYFDRGKRGQEFDY\n",
       "29    ERFVERHWVGRKRFDY\n",
       "30    DVPIVQVQGRSGVFDY\n",
       "31    DYIYFLRPHRTHWFDY\n",
       "32        EVRSPPQIQFDY\n",
       "33        DTYRRFIDSFDY\n",
       "34        ERAYYPLVYFDY\n",
       "35        EIRKTPLVFFDY\n",
       "36          DWPWYRALDY\n",
       "37    DSVRPDIPQWKLSFDY\n",
       "38        DQPWHPGATFDY\n",
       "39    PTPVYFSLTSYGIFDY\n",
       "40        EEQQWPLIYFDY\n",
       "41        ESSQYPLIKFDY\n",
       "42        EYTGWPLLYFDY\n",
       "43        EWRWPPLVSFDY\n",
       "44          DEPWYQIFDY\n",
       "45          DLPWGRVFDY\n",
       "46          DWPFHRYFDY\n",
       "47        VVDPVYWSDFDY\n",
       "Name: Sequence, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=result[\"Sequence\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By running the following set of processing transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step adds padding to length 20 evenly on the sequence\n",
    "pad=np.vectorize(pad_sequence)\n",
    "test=pad(test, \"J\", 20)\n",
    "test=test.astype(\"object\")\n",
    "\n",
    "# This performs one-hot encoding of data \n",
    "dat=process(test)\n",
    "dat=torch.tensor(np.array(dat),  dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute unrelated target predictions\n",
    "- Next, we generate predictions for each unrelated, sticky target using previously trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsa=compute_pred_labels(\"../experiments/bsa/\", dat).reshape(-1)\n",
    "bv=compute_pred_labels(\"../experiments/bv/\", dat).reshape(-1)\n",
    "tgfb=compute_pred_labels(\"../experiments/tgfb/\", dat).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this step, the final predictions are made. If a sequence binds **any** of the three sticky targets, it is labeled nonspecific. Otherwise it is labeled specific. As shown in the manuscript, the results of this align with the ELISA ('Ground-truth labels' column in result.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred=[]\n",
    "for i in range(48):\n",
    "    if bsa[i]==1 or tgfb[i]==1 or bv[i]==1:\n",
    "        final_pred.append(\"Non-specific\")\n",
    "    else:\n",
    "        final_pred.append(\"Anti-id (specific)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
